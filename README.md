## LLaMA-XL: LLaMA model Beyond Length Limitation 

[1] Found that RoPE plus bias can make a good long length generalization. Here, we freeze most of LLaMA parameters and train a bias adapter to improve the max length performance. 



## Reference 
[1] https://spaces.ac.cn/archives/9577 

